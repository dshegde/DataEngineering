{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Arial-ItalicMT;
\f3\froman\fcharset0 Times-Bold;\f4\fmodern\fcharset0 CourierNewPSMT;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;\red47\green50\blue64;
\red16\green60\blue192;\red254\green255\blue10;\red255\green255\blue255;\red255\green255\blue11;\red255\green255\blue255;
}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;\cssrgb\c23922\c25882\c31765;
\cssrgb\c6667\c33333\c80000;\cssrgb\c99555\c99475\c0;\cssrgb\c100000\c100000\c99971;\cssrgb\c100000\c100000\c0;\cssrgb\c100000\c100000\c99985;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2\'01\'01;}{\levelnumbers\'01;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid11}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\qc\partightenfactor0

\f0\fs69\fsmilli34667 \cf0 \cb2 \expnd0\expndtw0\kerning0
DataEng: Data Transport Activity
\f1\fs24 \
\pard\pardeftab720\qc\partightenfactor0

\f2\i\fs26\fsmilli13333 \cf4 [this lab activity references tutorials at confluence.com]
\f3\i0\b\fs48 \cf0 \
\pard\pardeftab720\partightenfactor0

\f0\b0\fs29\fsmilli14667 \cf0 \cb1 Make a copy of this document and use it to record your results. Store a PDF copy of the document in your git repository along with your code before submitting for this week. For your code, you create several producer/consumer programs or you might make various features within one program. There is no one single correct way to do it. Regardless, store your code in your repository.
\f1\fs24 \
\

\f0\fs29\fsmilli14667 The goal for this week is to gain experience and knowledge of using a streaming data transport system (Kafka). Complete as many of the following exercises as you can. Proceed at a pace that allows you to learn and understand the use of Kafka with python.\'a0
\f1\fs24 \
\
\pard\pardeftab720\partightenfactor0

\f0\fs37\fsmilli18667 \cf0 Submit: {\field{\*\fldinst{HYPERLINK "https://forms.gle/EYmcAh9mqrzNSU7d7"}}{\fldrslt \cf5 \ul \ulc5 In-class Activity Submission Form}}
\f1\fs24 \
\pard\pardeftab720\sa160\partightenfactor0

\f0\fs42\fsmilli21333 \cf0 A. Initialization
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f0\b0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Get your cloud.google.com account up and running\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls1\ilvl1\cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Redeem your GCP coupon\
\ls1\ilvl1\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Login to your GCP console\
\ls1\ilvl1\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Create a new, separate VM instance\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf0 \kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Follow the Kafka tutorial from project assignment #1\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\partightenfactor0
\ls1\ilvl1\cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Create a separate topic for this in-class activity\
\ls1\ilvl1\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Make it \'93small\'94 as you will not want to use many resources for this activity. By \'93small\'94 I mean that you should choose medium or minimal options when asked for any configuration decisions about the topic, cluster, partitions, storage, anything. GCP/Confluent will ask you to choose the configs, and because you are using a free account you should opt for limited resources where possible.\'a0\'a0\
\ls1\ilvl1\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Get a basic producer and consumer working with a Kafka topic as described in the tutorials.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf0 \kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Create a sample breadcrumb data file (named bcsample.json) consisting of a sample of 1000 breadcrumb records. These can be any records because we will not be concerned with the actual contents of the breadcrumb records during this assignment.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
Update your producer to parse your sample.json file and send its contents, one record at a time, to the kafka topic.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	5	}\expnd0\expndtw0\kerning0
Use your consumer.py program (from the tutorial) to consume your records.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\sa160\partightenfactor0

\f0\fs42\fsmilli21333 \cf0 B. Kafka Monitoring
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f0\b0\fs29\fsmilli14667 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Find the Kafka monitoring console for your topic. Briefly describe its contents. Do the measured values seem reasonable to you? \cf2 \cb6 Yes\cf0 \cb1 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Use this monitoring feature as you do each of the following exercises.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\sa160\partightenfactor0

\f0\fs42\fsmilli21333 \cf0 C. Kafka Storage
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f0\b0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Run the linux command \'93wc bcsample.json\'94.\'a0 Record the output here so that we can verify that your sample data file is of reasonable size. 
\f4\fs26 \AppleTypeServices\AppleTypeServicesF65539 \cf7 \cb8 \outl0\strokewidth0 \strokec7 0 1146 8963 consumerResult.json
\f0\fs32 \AppleTypeServices \cf0 \cb1 \outl0\strokewidth0 \
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0
\f0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
What happens if you run your consumer multiple times while only running the producer once? \cf2 \cb6 Second time no messages in the queue\cf0 \cb1 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Before the consumer runs, where might the data go, where might it be stored? \cf2 \cb6 In the topic message queue\cf0 \cb1 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
Is there a way to determine how much data Kafka/Confluent is storing for your topic? Do the Confluent monitoring tools help with this? \cf9 \cb8 Yes in the topic section of confluent cloud\cf0 \cb1 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 {\listtext	5	}\expnd0\expndtw0\kerning0
Create a \'93topic_clean.py\'94 consumer that reads and discards all records for a given topic. This type of program can be very useful during debugging.\
\pard\pardeftab720\sa160\partightenfactor0

\fs42\fsmilli21333 \cf0 D. Multiple Producers
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0
\f0\b0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Clear all data from the topic\
\ls5\ilvl0\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Run two versions of your producer concurrently, have each of them send all 1000 of your sample records. When finished, run your consumer once. Describe the results. \cf9 \cb8 It consumes 2*number of records produced by each producer run)\cf0 \cb1 \
\pard\pardeftab720\sa160\partightenfactor0

\fs42\fsmilli21333 \cf0 E. Multiple Concurrent Producers and Consumers
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls6\ilvl0
\f0\b0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Clear all data from the topic\
\ls6\ilvl0\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Update your Producer code to include a 250 msec sleep after each send of a message to the topic.\
\ls6\ilvl0\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Run two or three concurrent producers and two concurrent consumers all at the same time.\
\ls6\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
Describe the results.\
\pard\pardeftab720\sa160\partightenfactor0

\fs42\fsmilli21333 \cf0 F. Varying Keys
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0
\f0\b0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Clear all data from the topic\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf0 So far you have kept the \'93key\'94 value constant for each record sent on a topic. But keys can be very useful to choose specific records from a stream.
\f1\fs24 \

\f0\fs32 \'a0
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0
\f0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Update your producer code to choose a random number between 1 and 5 for each record\'92s key.\
\ls8\ilvl0\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Modify your consumer to consume only records with a specific key (or subset of keys).\
\ls8\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
Attempt to consume records with a key that does not exist. E.g., consume records with key value of \'93100\'94. Describe the results\
\ls8\ilvl0\kerning1\expnd0\expndtw0 {\listtext	5	}\expnd0\expndtw0\kerning0
Can you create a consumer that only consumes specific keys? If you run this consumer multiple times with varying keys then does it allow you to consume messages out of order while maintaining order within each key?\
\pard\pardeftab720\sa160\partightenfactor0

\fs42\fsmilli21333 \cf0 G. Producer Flush
\f3\b\fs36 \
\pard\pardeftab720\partightenfactor0

\f0\b0\fs32 \cf0 The provided tutorial producer program calls \'93producer.flush()\'94 at the very end, and presumably your new producer also calls producer.flush().\'a0
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0
\f0\fs32 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
What does Producer.flush() do?\'a0\
\ls9\ilvl0\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
What happens if you do not call producer.flush()?\'a0\'a0\
\ls9\ilvl0\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
What happens if you call producer.flush() after sending each record?\
\ls9\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
What happens if you wait for 2 seconds after every 5th record send, and you call flush only after every 15 record sends, and you have a consumer running concurrently?\'a0 Specifically, does the consumer receive each message immediately? only after a flush? Something else?\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\sa160\partightenfactor0

\f0\fs42\fsmilli21333 \cf0 H. Consumer Groups
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0
\f0\b0\fs29\fsmilli14667 \cf0 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
Create two consumer groups with one consumer program instance in each group.\
\ls10\ilvl0\kerning1\expnd0\expndtw0 {\listtext	2	}\expnd0\expndtw0\kerning0
Run the producer and have it produce all 1000 messages from your sample file.\
\ls10\ilvl0\kerning1\expnd0\expndtw0 {\listtext	3	}\expnd0\expndtw0\kerning0
Run each of the consumers and verify that each consumer consumes all of the 50 messages.\
\ls10\ilvl0\kerning1\expnd0\expndtw0 {\listtext	4	}\expnd0\expndtw0\kerning0
Create a second consumer within one of the groups so that you now have three consumers total.\
\ls10\ilvl0\kerning1\expnd0\expndtw0 {\listtext	5	}\expnd0\expndtw0\kerning0
Rerun the producer and consumers. Verify that each consumer group consumes the full set of messages but that each consumer within a consumer group only consumes a portion of the messages sent to the topic.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\sa160\partightenfactor0

\f0\fs42\fsmilli21333 \cf0 I. Kafka Transactions
\f3\b\fs36 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0
\f0\b0\fs29\fsmilli14667 \cf0 \kerning1\expnd0\expndtw0 {\listtext	6	}\expnd0\expndtw0\kerning0
Create a new producer, similar to the previous producer, that uses transactions.\
\ls11\ilvl0\kerning1\expnd0\expndtw0 {\listtext	7	}\expnd0\expndtw0\kerning0
The producer should begin a transaction, send 4 records in the transactions, then wait for 2 seconds, then choose True/False randomly with equal probability. If True then finish the transaction successfully with a commit.\'a0 If False is picked then cancel the transaction.\'a0\
\ls11\ilvl0\kerning1\expnd0\expndtw0 {\listtext	8	}\expnd0\expndtw0\kerning0
Create a new transaction-aware consumer. The consumer should consume the data. It should also use the Confluent/Kaka transaction API with a \'93read_committed\'94 isolation level. (I can\'92t find evidence of other isolation levels).\'a0\
\ls11\ilvl0\kerning1\expnd0\expndtw0 {\listtext	9	}\expnd0\expndtw0\kerning0
Transaction across multiple topics. Create a second topic and modify your producer to send two records to the first topic and two records to the second topic before randomly committing or canceling the transaction. Modify the consumer to consume from the two queues. Verify that it only consumes committed data and not uncommitted or canceled data.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \
}